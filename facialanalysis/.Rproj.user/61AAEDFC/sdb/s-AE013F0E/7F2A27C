{
    "collab_server" : "",
    "contents" : "\nlibrary(\"httr\")\nlibrary(\"imager\")\nlibrary(\"jpeg\")\n#read image data\n\nsetwd(\"C:/Users/xiayi_000/OneDrive/image analysis\")\n\n###########################\n#Facial recognition by MS API\n###############################\n\ngetFaceinfo<-function(img.path,key='1606515fad374e0baa2c415559085ff8') {\n  # Define Microsoft API URL to request data\n  baseUrl <- \"https://westcentralus.api.cognitive.microsoft.com/face/v1.0/detect\"\n  q <- \"?returnFaceId=true&returnFaceLandmarks=true&returnFaceAttributes=age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise\"\n  url <- paste(baseUrl,q, sep=\"\")\n  # Define key https://www.microsoft.com/cognitive-services/en-us/emotion-api)\n  emotionKEY = key\n  # Define image\n  mybody = upload_file(img.path)\n  # Request data from Microsoft\n  faceEMO = POST(url=url, \n                 body=mybody, \n                 add_headers(.headers =c('Content-Type'='application/octet-stream', \n                                         'Ocp-Apim-Subscription-Key'=key)\n                 ))\n  output<-httr::content(faceEMO)\n  return(output)\n}\n\n\n\n#test\n# im <- load.image(\"sample/image9.jpg\")\n# plot(im)\n# \n# output<-getFaceinfo(img.path=\"sample/image9.jpg\",key='e1ebb1487dd842709ad43f822b0cd639')\n# df=unlist(output, use.names=TRUE) \n\n\n\n####################\n# plot\n####################\n\nplotface<-function(path,output) {\n  df<-output\n  facepoint<-function(x,y,col=\"blue\") {\n    facex = df[ c(x)]\n    facey = df[ c(y)]\n    points(facex,facey, pch=19, col=col)\n  }\n  plot(load.image(path))\n  #nose\n  facepoint(\"faceLandmarks.noseTip.x\",\"faceLandmarks.noseTip.y\",col=\"red\")\n  # right pupil location\n  facepoint(\"faceLandmarks.pupilRight.x\",\"faceLandmarks.pupilRight.y\",col=\"green\")\n  # left pupil location\n  facepoint(\"faceLandmarks.pupilLeft.x\",\"faceLandmarks.pupilLeft.y\",col=\"green\")\n  # left mouth location\n  facepoint(\"faceLandmarks.mouthLeft.x\",\"faceLandmarks.mouthLeft.y\",col=\"blue\")\n  # right mouth location\n  facepoint(\"faceLandmarks.mouthRight.x\",\"faceLandmarks.mouthRight.y\",col=\"blue\")\n  # left eyebow out\n  facepoint(\"faceLandmarks.eyebrowLeftOuter.x\",\"faceLandmarks.eyebrowLeftOuter.y\",col=\"white\")\n  # left eyebow in\n  facepoint(\"faceLandmarks.eyebrowLeftInner.x\",\"faceLandmarks.eyebrowLeftInner.y\",col=\"white\")\n  \n  # right eyebow out\n  facepoint(\"faceLandmarks.eyebrowRightOuter.x\",\"faceLandmarks.eyebrowRightOuter.y\",col=\"white\")\n  # right eyebow in\n  facepoint(\"faceLandmarks.eyebrowRightInner.x\",\"faceLandmarks.eyebrowRightInner.y\",col=\"white\")\n}\n\n#test\noutput<-getFaceinfo(img.path=\"sample/image8.jpg\",key='e1ebb1487dd842709ad43f822b0cd639')\ndf=unlist(output, use.names=TRUE) \nwrite.csv(t(df),\"return.csv\")\nplotface(path=\"sample/image8.jpg\",df)\n\n\n\n###########################\n#Facial recognition by Face++\n###############################\n\nfaceplusplus<-function(img.path) {\n  a<-POST(\"https://api-us.faceplusplus.com/facepp/v3/detect\",\n          body=list(\n            \"api_key\" = \"i6aAp-TZNec1-HjPlzJS1oAaEcdRUHxi\",\n            \"api_secret\" = \"dwobv2uNCA0MvUNTNwIiEmqQEn8jGGLR\",\n            \"image_file\" =  upload_file(img.path),\n            \"return_landmark\" = \"1\",\n            \"return_attributes\" = \"gender,age,smiling,headpose,facequality,blur,eyestatus,emotion,ethnicity,beauty,mouthstatus,eyegaze\"\n          ),\n          verbose()\n  )\noutput<-httr::content(a)\ndf=unlist(output$faces, use.names=TRUE) \n\ndata=data.frame(\n  type=strsplit(names(df), \".\", fixed = TRUE) [[1]][1] ,\n  pos=strsplit(names(df), \".\", fixed = TRUE) [[1]][2] ,\n  coord=strsplit(names(df), \".\", fixed = TRUE) [[1]][3] ,\n  value=df\n)\n\ndata<-data.frame(lapply(data, as.character), stringsAsFactors=FALSE)\n\nfor (i in 1:length(df)) {\n  data[i,\"type\"]=strsplit(names(df), \".\", fixed = TRUE)[[i]][1]\n  data[i,\"pos\"]=strsplit(names(df), \".\", fixed = TRUE)[[i]][2]\n  data[i,\"coord\"]=strsplit(names(df), \".\", fixed = TRUE)[[i]][3]\n}\n\nlibrary(dplyr)\nfin<-data %>%\n  filter(coord==\"x\"|coord==\"y\") %>%\n  spread(coord,value)\nreturn(fin)\n}\n\nplotface<-function(path,output) {\n\n  plot(load.image(path))\n  \n}\n\noutput<-faceplusplus(img.path=\"sample/image10.jpg\")\n\nplot(load.image(\"sample/image10.jpg\"))\npoints(output$x,output$y, pch=19, col=\"black\")\npoints(as.character(as.numeric(output$x)-500)\n       ,output$y, pch=19, col=\"black\")\n\nplot()\npoints(output$x,output$y, pch=19, col=\"black\")\n\n\n\n",
    "created" : 1505054650349.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3234957324",
    "id" : "7F2A27C",
    "lastKnownWriteTime" : 1505053648,
    "last_content_update" : 1505053648,
    "path" : "~/OneDrive/image analysis/image.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}